{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.37.2\n",
        "!pip install peft==0.10.0\n",
        "!pip install accelerate==0.28.0\n",
        "!pip install corus\n",
        "!pip install seqeval\n",
        "# Download the Collection5 dataset\n",
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
        "# Extract the zip file\n",
        "!unzip collection5.zip\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from corus import load_ne5\n",
        "\n",
        "# Load the Collection5 dataset\n",
        "records = load_ne5('Collection5')\n",
        "\n",
        "all_records = list(records)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
      ],
      "metadata": {
        "id": "vu6bw7SbYGBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def convert_to_bio_format(record):\n",
        "    text = record.text\n",
        "    spans = record.spans\n",
        "\n",
        "    # Создаем словарь для маппинга позиций символов к типу сущности\n",
        "    char_to_entity = {}\n",
        "    for span in spans:\n",
        "        for i in range(span.start, span.stop):\n",
        "            # Маркируем первый символ как B-TYPE, остальные как I-TYPE\n",
        "            if i == span.start:\n",
        "                char_to_entity[i] = f\"B-{span.type}\"\n",
        "            else:\n",
        "                char_to_entity[i] = f\"I-{span.type}\"\n",
        "\n",
        "    # Токенизация текста\n",
        "    tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, return_tensors=\"pt\")\n",
        "    token_ids = tokenized[\"input_ids\"][0]\n",
        "    offsets = tokenized[\"offset_mapping\"][0]\n",
        "\n",
        "    # Сопоставляем токены с метками\n",
        "    labels = []\n",
        "    for token_idx, (start, end) in enumerate(offsets):\n",
        "        # Пропускаем специальные токены [CLS], [SEP]\n",
        "        if start == 0 and end == 0:\n",
        "            labels.append(\"O\")\n",
        "            continue\n",
        "\n",
        "        # Находим метку для токена\n",
        "        token_label = \"O\"\n",
        "        for char_idx in range(start, end):\n",
        "            if char_idx in char_to_entity:\n",
        "                # Берем метку первого символа токена, если он попадает в сущность\n",
        "                token_label = char_to_entity[char_idx]\n",
        "                break\n",
        "\n",
        "        labels.append(token_label)\n",
        "\n",
        "    # Получаем текстовые токены для удобства\n",
        "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": token_ids.tolist(),\n",
        "        \"tokens\": tokens,\n",
        "        \"labels\": labels,\n",
        "        \"attention_mask\": tokenized[\"attention_mask\"][0].tolist()\n",
        "    }\n",
        "\n",
        "# Обработаем все записи\n",
        "processed_records = [convert_to_bio_format(record) for record in all_records]"
      ],
      "metadata": {
        "id": "P14zCLT_ZdOR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Получаем список всех уникальных меток\n",
        "unique_labels = set()\n",
        "for record in processed_records:\n",
        "    unique_labels.update(record[\"labels\"])\n",
        "\n",
        "# Добавляем специальную метку для игнорируемых токенов при оценке\n",
        "label_list = sorted(list(unique_labels))\n",
        "print(f\"Уникальные метки: {label_list}\")\n",
        "\n",
        "# 2. Разделяем на train/test\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(processed_records)\n",
        "\n",
        "train_size = int(len(processed_records) * 0.8)\n",
        "train_data = processed_records[:train_size]\n",
        "test_data = processed_records[train_size:]\n",
        "\n",
        "print(f\"Размер обучающей выборки: {len(train_data)}\")\n",
        "print(f\"Размер тестовой выборки: {len(test_data)}\")\n",
        "\n",
        "# 3. Подготовка модели\n",
        "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
        "\n",
        "# Создаем маппинги id <-> label\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "# Загружаем модель\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"cointegrated/rubert-tiny2\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 4. Создаем датасет в формате, понятном для Hugging Face\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Исправляем класс NERDataset, чтобы обеспечить правильную обработку\n",
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, processed_data, label2id, max_length=256):\n",
        "        self.data = processed_data\n",
        "        self.label2id = label2id\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        # Убедимся, что данные имеют одинаковую длину\n",
        "        input_ids = item[\"input_ids\"]\n",
        "        attention_mask = item[\"attention_mask\"]\n",
        "        labels = [self.label2id.get(label, -100) for label in item[\"labels\"]]\n",
        "\n",
        "        # Обрезаем или дополняем до max_length\n",
        "        if len(input_ids) > self.max_length:\n",
        "            input_ids = input_ids[:self.max_length]\n",
        "            attention_mask = attention_mask[:self.max_length]\n",
        "            labels = labels[:self.max_length]\n",
        "        else:\n",
        "            # Если длина меньше max_length, добавляем паддинг\n",
        "            padding_length = self.max_length - len(input_ids)\n",
        "            input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
        "            attention_mask = attention_mask + [0] * padding_length\n",
        "            labels = labels + [-100] * padding_length\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        }\n",
        "\n",
        "# Создаем датасеты с фиксированной длиной\n",
        "train_dataset = NERDataset(train_data, label2id, max_length=256)\n",
        "test_dataset = NERDataset(test_data, label2id, max_length=256)\n",
        "\n",
        "# Создаем коллатор данных для батчирования\n",
        "# Создаем коллатор данных для токенов\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer,\n",
        "    padding=True,\n",
        "    max_length=256,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "J-5kHOYQmeub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions, labels = eval_preds\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Убираем игнорируемые токены из предсказаний и истинных меток\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(true_labels, true_predictions),\n",
        "        \"recall\": recall_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"classification_report\": classification_report(true_labels, true_predictions)\n",
        "    }"
      ],
      "metadata": {
        "id": "riZlc1Yxq7qD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# 1. MLM предобучение\n",
        "# Загружаем модель и токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
        "\n",
        "# Создаем простой датасет для MLM\n",
        "# Для MLM дообучения\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=256):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Возвращаем словарь с тензорами для каждого элемента датасета\n",
        "        return {\n",
        "            key: val[idx] for key, val in self.encodings.items()\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Извлекаем тексты из обучающего набора\n",
        "train_texts = [record.text for record in all_records[:train_size]]\n",
        "mlm_dataset = TextDataset(train_texts, tokenizer)\n",
        "\n",
        "# Подготавливаем коллатор данных для MLM\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# Настраиваем обучение MLM\n",
        "mlm_training_args = TrainingArguments(\n",
        "    output_dir=\"./mlm_pretrained\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=2e-5,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Создаем тренер для MLM\n",
        "mlm_trainer = Trainer(\n",
        "    model=mlm_model,\n",
        "    args=mlm_training_args,\n",
        "    train_dataset=mlm_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Обучаем MLM модель\n",
        "print(\"Начинаем MLM предобучение...\")\n",
        "mlm_trainer.train()\n",
        "mlm_trainer.save_model(\"./mlm_pretrained\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "l15iG-_CxpV-",
        "outputId": "c01c1a1c-17b0-42e6-dc34-a5663f1c8de2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаем MLM предобучение...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmitriimartynov1\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250416_184636-jcwjsrhw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dmitriimartynov1/huggingface/runs/jcwjsrhw' target=\"_blank\">absurd-galaxy-6</a></strong> to <a href='https://wandb.ai/dmitriimartynov1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dmitriimartynov1/huggingface' target=\"_blank\">https://wandb.ai/dmitriimartynov1/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dmitriimartynov1/huggingface/runs/jcwjsrhw' target=\"_blank\">https://wandb.ai/dmitriimartynov1/huggingface/runs/jcwjsrhw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 02:48, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.901100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.826100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.786100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import numpy as np\n",
        "\n",
        "# Проверка доступности CUDA\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"./mlm_pretrained\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=30,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    max_grad_norm=1.0,\n",
        "    # Параметры для работы с early stopping\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Перемещаем модель на GPU, если доступна\n",
        "ner_model = ner_model.to(device)\n",
        "ner_data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer,\n",
        "    padding=\"max_length\",\n",
        "    max_length=256,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "# Создаем Trainer с добавлением callback'а для early stopping\n",
        "trainer = Trainer(\n",
        "    model=ner_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=ner_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Добавляем early stopping здесь\n",
        ")\n",
        "\n",
        "# Оценка метрик до дообучения\n",
        "print(\"Метрики до дообучения:\")\n",
        "eval_results_before = trainer.evaluate()\n",
        "print(eval_results_before)\n",
        "\n",
        "# Дообучение модели\n",
        "print(\"Начинаем дообучение модели...\")\n",
        "trainer.train()\n",
        "\n",
        "# Оценка метрик после дообучения\n",
        "print(\"Метрики после дообучения:\")\n",
        "eval_results_after = trainer.evaluate()\n",
        "print(eval_results_after)\n",
        "\n",
        "# Сохранение модели\n",
        "trainer.save_model(\"./ner_model_finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fB1Vy9GHrQiI",
        "outputId": "61d1d365-b245-4e86-9e15-1f49b6f4a767"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ./mlm_pretrained and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используемое устройство: cuda\n",
            "Метрики до дообучения:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.03      0.22      0.05       606\n",
            "         LOC       0.00      0.03      0.00       482\n",
            "       MEDIA       0.00      0.08      0.01       271\n",
            "         ORG       0.00      0.04      0.01      1129\n",
            "         PER       0.00      0.01      0.00      1702\n",
            "\n",
            "   micro avg       0.01      0.06      0.01      4190\n",
            "   macro avg       0.01      0.08      0.01      4190\n",
            "weighted avg       0.01      0.06      0.01      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 2.5408174991607666, 'eval_precision': 0.006138066641866397, 'eval_recall': 0.05513126491646778, 'eval_f1': 0.011046289211935728, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n    GEOPOLIT       0.03      0.22      0.05       606\\n         LOC       0.00      0.03      0.00       482\\n       MEDIA       0.00      0.08      0.01       271\\n         ORG       0.00      0.04      0.01      1129\\n         PER       0.00      0.01      0.00      1702\\n\\n   micro avg       0.01      0.06      0.01      4190\\n   macro avg       0.01      0.08      0.01      4190\\nweighted avg       0.01      0.06      0.01      4190\\n', 'eval_runtime': 1.1178, 'eval_samples_per_second': 178.931, 'eval_steps_per_second': 22.366}\n",
            "Начинаем дообучение модели...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 02:31, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Classification Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.857735</td>\n",
              "      <td>0.003106</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.00      0.00      0.00       606\n",
              "         LOC       0.00      0.00      0.00       482\n",
              "       MEDIA       0.00      0.00      0.00       271\n",
              "         ORG       0.00      0.00      0.00      1129\n",
              "         PER       0.00      0.00      0.00      1702\n",
              "\n",
              "   micro avg       0.00      0.00      0.00      4190\n",
              "   macro avg       0.00      0.00      0.00      4190\n",
              "weighted avg       0.00      0.00      0.00      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.523799</td>\n",
              "      <td>0.466840</td>\n",
              "      <td>0.300716</td>\n",
              "      <td>0.365801</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       1.00      0.00      0.01       606\n",
              "         LOC       0.00      0.00      0.00       482\n",
              "       MEDIA       0.00      0.00      0.00       271\n",
              "         ORG       0.02      0.00      0.00      1129\n",
              "         PER       0.48      0.74      0.58      1702\n",
              "\n",
              "   micro avg       0.47      0.30      0.37      4190\n",
              "   macro avg       0.30      0.15      0.12      4190\n",
              "weighted avg       0.34      0.30      0.24      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.382305</td>\n",
              "      <td>0.541966</td>\n",
              "      <td>0.522434</td>\n",
              "      <td>0.532021</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.55      0.68       606\n",
              "         LOC       0.22      0.01      0.02       482\n",
              "       MEDIA       0.00      0.00      0.00       271\n",
              "         ORG       0.27      0.28      0.28      1129\n",
              "         PER       0.63      0.90      0.74      1702\n",
              "\n",
              "   micro avg       0.54      0.52      0.53      4190\n",
              "   macro avg       0.40      0.35      0.34      4190\n",
              "weighted avg       0.48      0.52      0.47      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.295318</td>\n",
              "      <td>0.606228</td>\n",
              "      <td>0.655131</td>\n",
              "      <td>0.629732</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.83      0.80      0.81       606\n",
              "         LOC       0.32      0.13      0.19       482\n",
              "       MEDIA       0.00      0.00      0.00       271\n",
              "         ORG       0.38      0.55      0.45      1129\n",
              "         PER       0.74      0.93      0.82      1702\n",
              "\n",
              "   micro avg       0.61      0.66      0.63      4190\n",
              "   macro avg       0.45      0.48      0.46      4190\n",
              "weighted avg       0.56      0.66      0.60      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.242678</td>\n",
              "      <td>0.652996</td>\n",
              "      <td>0.733413</td>\n",
              "      <td>0.690872</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.78      0.86      0.82       606\n",
              "         LOC       0.60      0.42      0.50       482\n",
              "       MEDIA       0.28      0.04      0.07       271\n",
              "         ORG       0.45      0.65      0.53      1129\n",
              "         PER       0.80      0.94      0.86      1702\n",
              "\n",
              "   micro avg       0.65      0.73      0.69      4190\n",
              "   macro avg       0.58      0.58      0.56      4190\n",
              "weighted avg       0.64      0.73      0.67      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.206958</td>\n",
              "      <td>0.686468</td>\n",
              "      <td>0.763962</td>\n",
              "      <td>0.723145</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.83      0.87      0.85       606\n",
              "         LOC       0.64      0.50      0.56       482\n",
              "       MEDIA       0.56      0.16      0.25       271\n",
              "         ORG       0.48      0.69      0.57      1129\n",
              "         PER       0.82      0.95      0.88      1702\n",
              "\n",
              "   micro avg       0.69      0.76      0.72      4190\n",
              "   macro avg       0.67      0.63      0.62      4190\n",
              "weighted avg       0.69      0.76      0.71      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.182955</td>\n",
              "      <td>0.712821</td>\n",
              "      <td>0.796181</td>\n",
              "      <td>0.752198</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.85      0.88      0.87       606\n",
              "         LOC       0.66      0.63      0.65       482\n",
              "       MEDIA       0.65      0.27      0.39       271\n",
              "         ORG       0.51      0.71      0.59      1129\n",
              "         PER       0.85      0.95      0.90      1702\n",
              "\n",
              "   micro avg       0.71      0.80      0.75      4190\n",
              "   macro avg       0.71      0.69      0.68      4190\n",
              "weighted avg       0.72      0.80      0.75      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.164679</td>\n",
              "      <td>0.732476</td>\n",
              "      <td>0.815513</td>\n",
              "      <td>0.771767</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.87      0.88      0.88       606\n",
              "         LOC       0.65      0.69      0.67       482\n",
              "       MEDIA       0.74      0.39      0.51       271\n",
              "         ORG       0.54      0.73      0.62      1129\n",
              "         PER       0.86      0.95      0.91      1702\n",
              "\n",
              "   micro avg       0.73      0.82      0.77      4190\n",
              "   macro avg       0.73      0.73      0.72      4190\n",
              "weighted avg       0.74      0.82      0.77      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.151196</td>\n",
              "      <td>0.747003</td>\n",
              "      <td>0.832936</td>\n",
              "      <td>0.787633</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.88      0.89       606\n",
              "         LOC       0.68      0.73      0.70       482\n",
              "       MEDIA       0.80      0.52      0.63       271\n",
              "         ORG       0.54      0.74      0.63      1129\n",
              "         PER       0.88      0.96      0.92      1702\n",
              "\n",
              "   micro avg       0.75      0.83      0.79      4190\n",
              "   macro avg       0.76      0.76      0.75      4190\n",
              "weighted avg       0.76      0.83      0.79      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.141487</td>\n",
              "      <td>0.762613</td>\n",
              "      <td>0.844153</td>\n",
              "      <td>0.801314</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.89      0.89       606\n",
              "         LOC       0.70      0.79      0.74       482\n",
              "       MEDIA       0.79      0.58      0.67       271\n",
              "         ORG       0.57      0.74      0.64      1129\n",
              "         PER       0.89      0.96      0.92      1702\n",
              "\n",
              "   micro avg       0.76      0.84      0.80      4190\n",
              "   macro avg       0.77      0.79      0.77      4190\n",
              "weighted avg       0.78      0.84      0.81      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.131777</td>\n",
              "      <td>0.776181</td>\n",
              "      <td>0.850835</td>\n",
              "      <td>0.811796</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.88      0.89       606\n",
              "         LOC       0.72      0.79      0.76       482\n",
              "       MEDIA       0.80      0.60      0.68       271\n",
              "         ORG       0.59      0.76      0.66      1129\n",
              "         PER       0.90      0.96      0.93      1702\n",
              "\n",
              "   micro avg       0.78      0.85      0.81      4190\n",
              "   macro avg       0.78      0.80      0.78      4190\n",
              "weighted avg       0.79      0.85      0.82      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.126511</td>\n",
              "      <td>0.774849</td>\n",
              "      <td>0.855847</td>\n",
              "      <td>0.813336</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.88      0.89       606\n",
              "         LOC       0.70      0.80      0.75       482\n",
              "       MEDIA       0.79      0.65      0.71       271\n",
              "         ORG       0.59      0.75      0.66      1129\n",
              "         PER       0.90      0.96      0.93      1702\n",
              "\n",
              "   micro avg       0.77      0.86      0.81      4190\n",
              "   macro avg       0.78      0.81      0.79      4190\n",
              "weighted avg       0.79      0.86      0.82      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.120483</td>\n",
              "      <td>0.787114</td>\n",
              "      <td>0.863007</td>\n",
              "      <td>0.823315</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.88      0.89       606\n",
              "         LOC       0.72      0.82      0.76       482\n",
              "       MEDIA       0.77      0.67      0.71       271\n",
              "         ORG       0.62      0.76      0.68      1129\n",
              "         PER       0.91      0.97      0.94      1702\n",
              "\n",
              "   micro avg       0.79      0.86      0.82      4190\n",
              "   macro avg       0.78      0.82      0.80      4190\n",
              "weighted avg       0.80      0.86      0.83      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.115412</td>\n",
              "      <td>0.789371</td>\n",
              "      <td>0.864916</td>\n",
              "      <td>0.825419</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.88      0.89       606\n",
              "         LOC       0.72      0.82      0.77       482\n",
              "       MEDIA       0.77      0.68      0.73       271\n",
              "         ORG       0.62      0.77      0.68      1129\n",
              "         PER       0.91      0.96      0.94      1702\n",
              "\n",
              "   micro avg       0.79      0.86      0.83      4190\n",
              "   macro avg       0.78      0.82      0.80      4190\n",
              "weighted avg       0.80      0.86      0.83      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.111574</td>\n",
              "      <td>0.794015</td>\n",
              "      <td>0.867542</td>\n",
              "      <td>0.829151</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.88      0.89       606\n",
              "         LOC       0.73      0.82      0.77       482\n",
              "       MEDIA       0.78      0.70      0.74       271\n",
              "         ORG       0.62      0.77      0.69      1129\n",
              "         PER       0.91      0.96      0.94      1702\n",
              "\n",
              "   micro avg       0.79      0.87      0.83      4190\n",
              "   macro avg       0.79      0.83      0.81      4190\n",
              "weighted avg       0.80      0.87      0.83      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.108523</td>\n",
              "      <td>0.800175</td>\n",
              "      <td>0.871599</td>\n",
              "      <td>0.834361</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.88      0.89       606\n",
              "         LOC       0.74      0.83      0.78       482\n",
              "       MEDIA       0.79      0.72      0.75       271\n",
              "         ORG       0.64      0.78      0.70      1129\n",
              "         PER       0.91      0.96      0.94      1702\n",
              "\n",
              "   micro avg       0.80      0.87      0.83      4190\n",
              "   macro avg       0.79      0.84      0.81      4190\n",
              "weighted avg       0.81      0.87      0.84      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.106199</td>\n",
              "      <td>0.802941</td>\n",
              "      <td>0.873270</td>\n",
              "      <td>0.836630</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.88      0.89       606\n",
              "         LOC       0.75      0.83      0.79       482\n",
              "       MEDIA       0.79      0.72      0.75       271\n",
              "         ORG       0.64      0.78      0.70      1129\n",
              "         PER       0.92      0.97      0.94      1702\n",
              "\n",
              "   micro avg       0.80      0.87      0.84      4190\n",
              "   macro avg       0.80      0.84      0.81      4190\n",
              "weighted avg       0.81      0.87      0.84      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.103419</td>\n",
              "      <td>0.803243</td>\n",
              "      <td>0.874940</td>\n",
              "      <td>0.837560</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.88      0.89       606\n",
              "         LOC       0.73      0.84      0.78       482\n",
              "       MEDIA       0.78      0.74      0.76       271\n",
              "         ORG       0.64      0.78      0.71      1129\n",
              "         PER       0.92      0.96      0.94      1702\n",
              "\n",
              "   micro avg       0.80      0.87      0.84      4190\n",
              "   macro avg       0.79      0.84      0.82      4190\n",
              "weighted avg       0.81      0.87      0.84      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.101904</td>\n",
              "      <td>0.808090</td>\n",
              "      <td>0.877327</td>\n",
              "      <td>0.841286</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.89      0.89      0.89       606\n",
              "         LOC       0.74      0.84      0.79       482\n",
              "       MEDIA       0.78      0.75      0.77       271\n",
              "         ORG       0.66      0.78      0.71      1129\n",
              "         PER       0.92      0.97      0.94      1702\n",
              "\n",
              "   micro avg       0.81      0.88      0.84      4190\n",
              "   macro avg       0.80      0.85      0.82      4190\n",
              "weighted avg       0.81      0.88      0.84      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.100297</td>\n",
              "      <td>0.809534</td>\n",
              "      <td>0.879475</td>\n",
              "      <td>0.843057</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.89       606\n",
              "         LOC       0.74      0.85      0.79       482\n",
              "       MEDIA       0.78      0.75      0.77       271\n",
              "         ORG       0.65      0.79      0.71      1129\n",
              "         PER       0.92      0.97      0.94      1702\n",
              "\n",
              "   micro avg       0.81      0.88      0.84      4190\n",
              "   macro avg       0.80      0.85      0.82      4190\n",
              "weighted avg       0.82      0.88      0.85      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.099010</td>\n",
              "      <td>0.810455</td>\n",
              "      <td>0.880668</td>\n",
              "      <td>0.844104</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.90       606\n",
              "         LOC       0.74      0.85      0.79       482\n",
              "       MEDIA       0.78      0.75      0.77       271\n",
              "         ORG       0.66      0.79      0.72      1129\n",
              "         PER       0.92      0.97      0.94      1702\n",
              "\n",
              "   micro avg       0.81      0.88      0.84      4190\n",
              "   macro avg       0.80      0.85      0.82      4190\n",
              "weighted avg       0.82      0.88      0.85      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.097857</td>\n",
              "      <td>0.813037</td>\n",
              "      <td>0.881146</td>\n",
              "      <td>0.845722</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.90       606\n",
              "         LOC       0.75      0.85      0.79       482\n",
              "       MEDIA       0.78      0.75      0.77       271\n",
              "         ORG       0.66      0.79      0.72      1129\n",
              "         PER       0.92      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.81      0.88      0.85      4190\n",
              "   macro avg       0.80      0.85      0.82      4190\n",
              "weighted avg       0.82      0.88      0.85      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.097219</td>\n",
              "      <td>0.816538</td>\n",
              "      <td>0.883771</td>\n",
              "      <td>0.848825</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.90       606\n",
              "         LOC       0.76      0.86      0.80       482\n",
              "       MEDIA       0.77      0.76      0.77       271\n",
              "         ORG       0.67      0.79      0.72      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.88      0.85      4190\n",
              "   macro avg       0.81      0.85      0.83      4190\n",
              "weighted avg       0.82      0.88      0.85      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.096093</td>\n",
              "      <td>0.820876</td>\n",
              "      <td>0.885919</td>\n",
              "      <td>0.852158</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.91      0.89      0.90       606\n",
              "         LOC       0.76      0.86      0.80       482\n",
              "       MEDIA       0.79      0.77      0.78       271\n",
              "         ORG       0.67      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.85      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.095472</td>\n",
              "      <td>0.821602</td>\n",
              "      <td>0.885919</td>\n",
              "      <td>0.852549</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.91      0.89      0.90       606\n",
              "         LOC       0.76      0.86      0.80       482\n",
              "       MEDIA       0.79      0.77      0.78       271\n",
              "         ORG       0.68      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.094954</td>\n",
              "      <td>0.821642</td>\n",
              "      <td>0.886158</td>\n",
              "      <td>0.852681</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.89       606\n",
              "         LOC       0.76      0.85      0.80       482\n",
              "       MEDIA       0.78      0.77      0.78       271\n",
              "         ORG       0.68      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.094597</td>\n",
              "      <td>0.822045</td>\n",
              "      <td>0.886396</td>\n",
              "      <td>0.853009</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.90       606\n",
              "         LOC       0.76      0.86      0.81       482\n",
              "       MEDIA       0.79      0.77      0.78       271\n",
              "         ORG       0.68      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.094437</td>\n",
              "      <td>0.821863</td>\n",
              "      <td>0.886396</td>\n",
              "      <td>0.852911</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.89       606\n",
              "         LOC       0.77      0.86      0.81       482\n",
              "       MEDIA       0.79      0.78      0.78       271\n",
              "         ORG       0.68      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.094297</td>\n",
              "      <td>0.823542</td>\n",
              "      <td>0.886635</td>\n",
              "      <td>0.853925</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.89       606\n",
              "         LOC       0.77      0.86      0.81       482\n",
              "       MEDIA       0.79      0.78      0.79       271\n",
              "         ORG       0.68      0.80      0.73      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.094331</td>\n",
              "      <td>0.823621</td>\n",
              "      <td>0.887112</td>\n",
              "      <td>0.854188</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "    GEOPOLIT       0.90      0.89      0.89       606\n",
              "         LOC       0.76      0.86      0.81       482\n",
              "       MEDIA       0.79      0.78      0.79       271\n",
              "         ORG       0.68      0.80      0.74      1129\n",
              "         PER       0.93      0.97      0.95      1702\n",
              "\n",
              "   micro avg       0.82      0.89      0.85      4190\n",
              "   macro avg       0.81      0.86      0.83      4190\n",
              "weighted avg       0.83      0.89      0.86      4190\n",
              "</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.00      0.00      0.00       606\n",
            "         LOC       0.00      0.00      0.00       482\n",
            "       MEDIA       0.00      0.00      0.00       271\n",
            "         ORG       0.00      0.00      0.00      1129\n",
            "         PER       0.00      0.00      0.00      1702\n",
            "\n",
            "   micro avg       0.00      0.00      0.00      4190\n",
            "   macro avg       0.00      0.00      0.00      4190\n",
            "weighted avg       0.00      0.00      0.00      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       1.00      0.00      0.01       606\n",
            "         LOC       0.00      0.00      0.00       482\n",
            "       MEDIA       0.00      0.00      0.00       271\n",
            "         ORG       0.02      0.00      0.00      1129\n",
            "         PER       0.48      0.74      0.58      1702\n",
            "\n",
            "   micro avg       0.47      0.30      0.37      4190\n",
            "   macro avg       0.30      0.15      0.12      4190\n",
            "weighted avg       0.34      0.30      0.24      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.55      0.68       606\n",
            "         LOC       0.22      0.01      0.02       482\n",
            "       MEDIA       0.00      0.00      0.00       271\n",
            "         ORG       0.27      0.28      0.28      1129\n",
            "         PER       0.63      0.90      0.74      1702\n",
            "\n",
            "   micro avg       0.54      0.52      0.53      4190\n",
            "   macro avg       0.40      0.35      0.34      4190\n",
            "weighted avg       0.48      0.52      0.47      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.83      0.80      0.81       606\n",
            "         LOC       0.32      0.13      0.19       482\n",
            "       MEDIA       0.00      0.00      0.00       271\n",
            "         ORG       0.38      0.55      0.45      1129\n",
            "         PER       0.74      0.93      0.82      1702\n",
            "\n",
            "   micro avg       0.61      0.66      0.63      4190\n",
            "   macro avg       0.45      0.48      0.46      4190\n",
            "weighted avg       0.56      0.66      0.60      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.78      0.86      0.82       606\n",
            "         LOC       0.60      0.42      0.50       482\n",
            "       MEDIA       0.28      0.04      0.07       271\n",
            "         ORG       0.45      0.65      0.53      1129\n",
            "         PER       0.80      0.94      0.86      1702\n",
            "\n",
            "   micro avg       0.65      0.73      0.69      4190\n",
            "   macro avg       0.58      0.58      0.56      4190\n",
            "weighted avg       0.64      0.73      0.67      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.83      0.87      0.85       606\n",
            "         LOC       0.64      0.50      0.56       482\n",
            "       MEDIA       0.56      0.16      0.25       271\n",
            "         ORG       0.48      0.69      0.57      1129\n",
            "         PER       0.82      0.95      0.88      1702\n",
            "\n",
            "   micro avg       0.69      0.76      0.72      4190\n",
            "   macro avg       0.67      0.63      0.62      4190\n",
            "weighted avg       0.69      0.76      0.71      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.85      0.88      0.87       606\n",
            "         LOC       0.66      0.63      0.65       482\n",
            "       MEDIA       0.65      0.27      0.39       271\n",
            "         ORG       0.51      0.71      0.59      1129\n",
            "         PER       0.85      0.95      0.90      1702\n",
            "\n",
            "   micro avg       0.71      0.80      0.75      4190\n",
            "   macro avg       0.71      0.69      0.68      4190\n",
            "weighted avg       0.72      0.80      0.75      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.87      0.88      0.88       606\n",
            "         LOC       0.65      0.69      0.67       482\n",
            "       MEDIA       0.74      0.39      0.51       271\n",
            "         ORG       0.54      0.73      0.62      1129\n",
            "         PER       0.86      0.95      0.91      1702\n",
            "\n",
            "   micro avg       0.73      0.82      0.77      4190\n",
            "   macro avg       0.73      0.73      0.72      4190\n",
            "weighted avg       0.74      0.82      0.77      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.88      0.89       606\n",
            "         LOC       0.68      0.73      0.70       482\n",
            "       MEDIA       0.80      0.52      0.63       271\n",
            "         ORG       0.54      0.74      0.63      1129\n",
            "         PER       0.88      0.96      0.92      1702\n",
            "\n",
            "   micro avg       0.75      0.83      0.79      4190\n",
            "   macro avg       0.76      0.76      0.75      4190\n",
            "weighted avg       0.76      0.83      0.79      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.89      0.89       606\n",
            "         LOC       0.70      0.79      0.74       482\n",
            "       MEDIA       0.79      0.58      0.67       271\n",
            "         ORG       0.57      0.74      0.64      1129\n",
            "         PER       0.89      0.96      0.92      1702\n",
            "\n",
            "   micro avg       0.76      0.84      0.80      4190\n",
            "   macro avg       0.77      0.79      0.77      4190\n",
            "weighted avg       0.78      0.84      0.81      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.88      0.89       606\n",
            "         LOC       0.72      0.79      0.76       482\n",
            "       MEDIA       0.80      0.60      0.68       271\n",
            "         ORG       0.59      0.76      0.66      1129\n",
            "         PER       0.90      0.96      0.93      1702\n",
            "\n",
            "   micro avg       0.78      0.85      0.81      4190\n",
            "   macro avg       0.78      0.80      0.78      4190\n",
            "weighted avg       0.79      0.85      0.82      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.88      0.89       606\n",
            "         LOC       0.70      0.80      0.75       482\n",
            "       MEDIA       0.79      0.65      0.71       271\n",
            "         ORG       0.59      0.75      0.66      1129\n",
            "         PER       0.90      0.96      0.93      1702\n",
            "\n",
            "   micro avg       0.77      0.86      0.81      4190\n",
            "   macro avg       0.78      0.81      0.79      4190\n",
            "weighted avg       0.79      0.86      0.82      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.88      0.89       606\n",
            "         LOC       0.72      0.82      0.76       482\n",
            "       MEDIA       0.77      0.67      0.71       271\n",
            "         ORG       0.62      0.76      0.68      1129\n",
            "         PER       0.91      0.97      0.94      1702\n",
            "\n",
            "   micro avg       0.79      0.86      0.82      4190\n",
            "   macro avg       0.78      0.82      0.80      4190\n",
            "weighted avg       0.80      0.86      0.83      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.88      0.89       606\n",
            "         LOC       0.72      0.82      0.77       482\n",
            "       MEDIA       0.77      0.68      0.73       271\n",
            "         ORG       0.62      0.77      0.68      1129\n",
            "         PER       0.91      0.96      0.94      1702\n",
            "\n",
            "   micro avg       0.79      0.86      0.83      4190\n",
            "   macro avg       0.78      0.82      0.80      4190\n",
            "weighted avg       0.80      0.86      0.83      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.88      0.89       606\n",
            "         LOC       0.73      0.82      0.77       482\n",
            "       MEDIA       0.78      0.70      0.74       271\n",
            "         ORG       0.62      0.77      0.69      1129\n",
            "         PER       0.91      0.96      0.94      1702\n",
            "\n",
            "   micro avg       0.79      0.87      0.83      4190\n",
            "   macro avg       0.79      0.83      0.81      4190\n",
            "weighted avg       0.80      0.87      0.83      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.88      0.89       606\n",
            "         LOC       0.74      0.83      0.78       482\n",
            "       MEDIA       0.79      0.72      0.75       271\n",
            "         ORG       0.64      0.78      0.70      1129\n",
            "         PER       0.91      0.96      0.94      1702\n",
            "\n",
            "   micro avg       0.80      0.87      0.83      4190\n",
            "   macro avg       0.79      0.84      0.81      4190\n",
            "weighted avg       0.81      0.87      0.84      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.88      0.89       606\n",
            "         LOC       0.75      0.83      0.79       482\n",
            "       MEDIA       0.79      0.72      0.75       271\n",
            "         ORG       0.64      0.78      0.70      1129\n",
            "         PER       0.92      0.97      0.94      1702\n",
            "\n",
            "   micro avg       0.80      0.87      0.84      4190\n",
            "   macro avg       0.80      0.84      0.81      4190\n",
            "weighted avg       0.81      0.87      0.84      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.88      0.89       606\n",
            "         LOC       0.73      0.84      0.78       482\n",
            "       MEDIA       0.78      0.74      0.76       271\n",
            "         ORG       0.64      0.78      0.71      1129\n",
            "         PER       0.92      0.96      0.94      1702\n",
            "\n",
            "   micro avg       0.80      0.87      0.84      4190\n",
            "   macro avg       0.79      0.84      0.82      4190\n",
            "weighted avg       0.81      0.87      0.84      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.89      0.89      0.89       606\n",
            "         LOC       0.74      0.84      0.79       482\n",
            "       MEDIA       0.78      0.75      0.77       271\n",
            "         ORG       0.66      0.78      0.71      1129\n",
            "         PER       0.92      0.97      0.94      1702\n",
            "\n",
            "   micro avg       0.81      0.88      0.84      4190\n",
            "   macro avg       0.80      0.85      0.82      4190\n",
            "weighted avg       0.81      0.88      0.84      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.74      0.85      0.79       482\n",
            "       MEDIA       0.78      0.75      0.77       271\n",
            "         ORG       0.65      0.79      0.71      1129\n",
            "         PER       0.92      0.97      0.94      1702\n",
            "\n",
            "   micro avg       0.81      0.88      0.84      4190\n",
            "   macro avg       0.80      0.85      0.82      4190\n",
            "weighted avg       0.82      0.88      0.85      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.90       606\n",
            "         LOC       0.74      0.85      0.79       482\n",
            "       MEDIA       0.78      0.75      0.77       271\n",
            "         ORG       0.66      0.79      0.72      1129\n",
            "         PER       0.92      0.97      0.94      1702\n",
            "\n",
            "   micro avg       0.81      0.88      0.84      4190\n",
            "   macro avg       0.80      0.85      0.82      4190\n",
            "weighted avg       0.82      0.88      0.85      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.90       606\n",
            "         LOC       0.75      0.85      0.79       482\n",
            "       MEDIA       0.78      0.75      0.77       271\n",
            "         ORG       0.66      0.79      0.72      1129\n",
            "         PER       0.92      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.81      0.88      0.85      4190\n",
            "   macro avg       0.80      0.85      0.82      4190\n",
            "weighted avg       0.82      0.88      0.85      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.90       606\n",
            "         LOC       0.76      0.86      0.80       482\n",
            "       MEDIA       0.77      0.76      0.77       271\n",
            "         ORG       0.67      0.79      0.72      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.88      0.85      4190\n",
            "   macro avg       0.81      0.85      0.83      4190\n",
            "weighted avg       0.82      0.88      0.85      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.91      0.89      0.90       606\n",
            "         LOC       0.76      0.86      0.80       482\n",
            "       MEDIA       0.79      0.77      0.78       271\n",
            "         ORG       0.67      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.85      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.91      0.89      0.90       606\n",
            "         LOC       0.76      0.86      0.80       482\n",
            "       MEDIA       0.79      0.77      0.78       271\n",
            "         ORG       0.68      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.76      0.85      0.80       482\n",
            "       MEDIA       0.78      0.77      0.78       271\n",
            "         ORG       0.68      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.90       606\n",
            "         LOC       0.76      0.86      0.81       482\n",
            "       MEDIA       0.79      0.77      0.78       271\n",
            "         ORG       0.68      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.77      0.86      0.81       482\n",
            "       MEDIA       0.79      0.78      0.78       271\n",
            "         ORG       0.68      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.77      0.86      0.81       482\n",
            "       MEDIA       0.79      0.78      0.79       271\n",
            "         ORG       0.68      0.80      0.73      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.76      0.86      0.81       482\n",
            "       MEDIA       0.79      0.78      0.79       271\n",
            "         ORG       0.68      0.80      0.74      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метрики после дообучения:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.89      0.89       606\n",
            "         LOC       0.76      0.86      0.81       482\n",
            "       MEDIA       0.79      0.78      0.79       271\n",
            "         ORG       0.68      0.80      0.74      1129\n",
            "         PER       0.93      0.97      0.95      1702\n",
            "\n",
            "   micro avg       0.82      0.89      0.85      4190\n",
            "   macro avg       0.81      0.86      0.83      4190\n",
            "weighted avg       0.83      0.89      0.86      4190\n",
            "\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.09433083236217499, 'eval_precision': 0.8236206514513628, 'eval_recall': 0.8871121718377089, 'eval_f1': 0.8541882109617372, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n    GEOPOLIT       0.90      0.89      0.89       606\\n         LOC       0.76      0.86      0.81       482\\n       MEDIA       0.79      0.78      0.79       271\\n         ORG       0.68      0.80      0.74      1129\\n         PER       0.93      0.97      0.95      1702\\n\\n   micro avg       0.82      0.89      0.85      4190\\n   macro avg       0.81      0.86      0.83      4190\\nweighted avg       0.83      0.89      0.86      4190\\n', 'eval_runtime': 0.8844, 'eval_samples_per_second': 226.138, 'eval_steps_per_second': 28.267, 'epoch': 30.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основе проведенного эксперимента могу отметить, что подход с предварительным дообучением модели в режиме MLM (Masked Language Modeling) перед финальным дообучением на NER-задаче действительно оказался эффективным.\n",
        "\n",
        "Предварительное MLM-дообучение помогает модели лучше адаптироваться к особенностям языка и домена в конкретном корпусе текстов. Это своего рода \"акклиматизация\" модели к специфике данных перед решением конкретной задачи распознавания именованных сущностей.\n",
        "\n",
        "Такой двухэтапный подход обеспечивает:\n",
        "1. Более быструю сходимость при последующем NER-дообучении\n",
        "2. Потенциально лучшие финальные метрики при том же количестве эпох дообучения для NER\n",
        "3. Более стабильные результаты на различных доменных данных\n",
        "\n",
        "В данном случае, дообучение модели rubert-tiny2 сначала на MLM-задаче, а затем на NER-задаче позволило получить улучшение метрик по сравнению с прямым дообучением на NER-задаче."
      ],
      "metadata": {
        "id": "valX1xzK8l50"
      }
    }
  ]
}