{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "ieDclxkcMN80",
        "outputId": "d60bbd9c-8221-4169-9531-31a518bb6e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a0df654c033831659ccd7b20b0721fdca89826ed1e95e3b3d5ac103f232c1716\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lenta-ru-news.csv.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "# Download the dataset\n",
        "url = 'https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz'\n",
        "wget.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "\n",
        "df = pd.read_csv(\n",
        "    gzip.open(path, 'rt', encoding='utf-8'),\n",
        "    delimiter=',',\n",
        "    quotechar='\"'\n",
        ")\n",
        "\n",
        "df = df[['title', 'text', 'topic']].head(50000)\n",
        "\n",
        "class_counts = df['topic'].value_counts()\n",
        "valid_classes = class_counts[class_counts > 500].index.to_list()\n",
        "df = df[df['topic'].isin(valid_classes)]"
      ],
      "metadata": {
        "id": "OSpIHLgEMyiw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "714oRhD8jZVY",
        "outputId": "c856da17-d5aa-4e78-d5cb-a83686acdf94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pymorphy2 (from natasha)\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting razdel>=0.5.0 (from natasha)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting yargy>=0.16.0 (from natasha)\n",
            "  Downloading yargy-0.16.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec>=0.9.0->natasha) (1.26.4)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2->natasha)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2->natasha)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2->natasha)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Downloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt, intervaltree\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=74ea96b974a29b58e70b80ad91fe11e1e84742b171d5c831c3933ea92671ee55\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=dcd3ab88bee626a463ba3e97502cbd154fdfc8474aa970d34077a97ad3670fda\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built docopt intervaltree\n",
            "Installing collected packages: razdel, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.6.0 yargy-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from natasha import Doc, Segmenter, MorphVocab, NewsMorphTagger, NewsEmbedding\n",
        "emb = NewsEmbedding()\n",
        "morph_vocab = MorphVocab()\n",
        "segmenter = Segmenter(emb)\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "import re\n",
        "\n",
        "def normalize(text):\n",
        "    if not isinstance(text, str) or pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        # Приведение к нижнему регистру\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Удаление URL\n",
        "        clean_text = re.sub(r'https?://\\S+|www\\.\\S+', '', text_lower)\n",
        "\n",
        "        # Удаление email\n",
        "        clean_text = re.sub(r'\\S+@\\S+', '', clean_text)\n",
        "\n",
        "        # Удаление всех чисел\n",
        "        clean_text = re.sub(r'\\d+', '', clean_text)\n",
        "\n",
        "        # Удаление пунктуации\n",
        "        clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
        "\n",
        "        # Удаление множественных пробелов\n",
        "        clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
        "\n",
        "        # Создание документа\n",
        "        doc = Doc(clean_text)\n",
        "        doc.segment(segmenter)\n",
        "        doc.tag_morph(morph_tagger)\n",
        "\n",
        "        lemmatized_tokens = []\n",
        "        for token in doc.tokens:\n",
        "            try:\n",
        "                token.lemmatize(morph_vocab)\n",
        "                if hasattr(token, 'lemma') and token.lemma:\n",
        "                    lemmatized_tokens.append(token.lemma)\n",
        "                else:\n",
        "                    lemmatized_tokens.append(token.text)\n",
        "            except AttributeError:\n",
        "                lemmatized_tokens.append(token.text)\n",
        "\n",
        "        # Собираем результат\n",
        "        lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "        return lemmatized_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке текста: {str(e)}\")\n",
        "        return clean_text"
      ],
      "metadata": {
        "id": "P_4H9CazVZm2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['normalized_text'] = df['text'].apply(normalize)\n",
        "df['normalized_title'] = df['title'].apply(normalize)"
      ],
      "metadata": {
        "id": "KzVBbFQs1fPr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = df[['normalized_text', 'normalized_title', 'topic']]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_topics = label_encoder.fit_transform(dataset['topic'])\n",
        "\n",
        "y = encoded_topics\n",
        "X = dataset['normalized_title'] + ' ' + dataset['normalized_text']\n",
        "\n",
        "X_train, X_prep, y_train, y_prep  = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_prep, y_prep, test_size=0.5, random_state=1)\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "3Z3dqrknlVej",
        "outputId": "a289f9c4-bd64-4e4c-ad7c-86d372367ce5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        назвать регион россия с сам высокий смертность...\n",
              "1        австрия не представить доказательство вина рос...\n",
              "2        обнаружить самый счастливый место на планета с...\n",
              "3        в сша раскрыть сумма расход на расследование р...\n",
              "4        хакер рассказать о план великобритания заминир...\n",
              "                               ...                        \n",
              "49995    в великобритания арестовать мужчина за секс с ...\n",
              "49996    создать эффективный способ лечение смертоносны...\n",
              "49997    защитник сборная россия спасти ворота кельн в ...\n",
              "49998    летний хипстерполицейский покорить instagram и...\n",
              "49999    кубинский власть назвать источник акустический...\n",
              "Length: 49337, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>назвать регион россия с сам высокий смертность...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>австрия не представить доказательство вина рос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>обнаружить самый счастливый место на планета с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>в сша раскрыть сумма расход на расследование р...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>хакер рассказать о план великобритания заминир...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>в великобритания арестовать мужчина за секс с ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>создать эффективный способ лечение смертоносны...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>защитник сборная россия спасти ворота кельн в ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>летний хипстерполицейский покорить instagram и...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>кубинский власть назвать источник акустический...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49337 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRz20K8dlgTL",
        "outputId": "8741052f-5439-4d9b-f03f-94b57ad9490e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = []\n",
        "for text in X_train:\n",
        "    tokens = text.split()\n",
        "    tokenized_texts.append(tokens)\n",
        "\n",
        "# Обучаем модель word2vec\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_texts,\n",
        "    vector_size=300,  # размерность векторов\n",
        "    window=7,         # размер окна контекста\n",
        "    min_count=5,      # минимальная частота слова\n",
        "    workers=4,        # число потоков для параллельного обучения\n",
        "    sg=1,             # 1 = skip-gram; 0 = CBOW\n",
        "    seed=1,\n",
        "    epochs=10,\n",
        "    compute_loss=True,\n",
        ")\n",
        "\n",
        "training_loss = w2v_model.get_latest_training_loss()\n",
        "print(training_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AftyeM06caKD",
        "outputId": "8a904ee6-883b-4937-ab74-80db06ce5e91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67934632.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала обучил на дефолтных параметрах затем увеличил размер окна, добавил больше эпох и сменил на скип грам"
      ],
      "metadata": {
        "id": "u4nqya6XkEN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"w2v_model.model\")"
      ],
      "metadata": {
        "id": "8G9OzLq6jwhS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = w2v_model.wv\n",
        "\n",
        "word_vectors.doesnt_match(\"завтрак тарелка ужин обед\".split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ulxQasHekaPH",
        "outputId": "c516b905-25a2-4521-fea9-7aec5133ef5b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'тарелка'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = word_vectors.most_similar(positive=['женщина', 'король'], negative=['мужчина'])\n",
        "most_similar_key, similarity = result[0]  # look at the first match\n",
        "print(f\"{most_similar_key}: {similarity:.4f}\")\n",
        "queen: 0.7699"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX6XVOeumPCr",
        "outputId": "229bfbe2-4462-4419-876d-f1f6a7c19876"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "бритт: 0.4519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import gensim\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\",\n",
        "    \"ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\"\n",
        ")\n",
        "\n",
        "model_path = 'ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz'\n",
        "model_rusvectores = gensim.models.KeyedVectors.load_word2vec_format(model_path)"
      ],
      "metadata": {
        "id": "cfCDEDKgRr4h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install navec\n",
        "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
        "from navec import Navec\n",
        "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
        "model_navec = Navec.load(path)\n",
        "model_navec['человек'][:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zd42Fwv-WIy",
        "outputId": "204c703f-c1f8-4bcf-916f-7cfdf872cfd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: navec in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec) (1.26.4)\n",
            "--2025-03-14 05:59:34--  https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26634240 (25M) [application/x-tar]\n",
            "Saving to: ‘navec_news_v1_1B_250K_300d_100q.tar’\n",
            "\n",
            "navec_news_v1_1B_25 100%[===================>]  25.40M  7.78MB/s    in 4.8s    \n",
            "\n",
            "2025-03-14 05:59:40 (5.24 MB/s) - ‘navec_news_v1_1B_250K_300d_100q.tar’ saved [26634240/26634240]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.13068067, -0.12051002, -0.05782367,  0.07967507,  0.08338855,\n",
              "        0.59920526,  0.4020081 , -1.0838276 ,  0.12556174,  0.17060532,\n",
              "        0.16637331, -0.00257014,  0.51296437,  0.17175263, -0.40394753],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Функция для получения усредненного вектора текста\n",
        "def get_text_vector(text, model, size=300):\n",
        "    tokens = text.split()\n",
        "    vectors = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in model:  # Проверяем, есть ли слово в модели\n",
        "            vectors.append(model[token])\n",
        "\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(size)  # Если ни одно слово не найдено, возвращаем нулевой вектор\n",
        "\n",
        "# Создаем векторные представления для каждой модели\n",
        "# 1. Наша обученная модель\n",
        "X_train_w2v = np.array([get_text_vector(text, w2v_model.wv) for text in X_train])\n",
        "X_val_w2v = np.array([get_text_vector(text, w2v_model.wv) for text in X_val])\n",
        "X_test_w2v = np.array([get_text_vector(text, w2v_model.wv) for text in X_test])\n",
        "\n",
        "# 2. RusVectores\n",
        "X_train_rusvec = np.array([get_text_vector(text, model_rusvectores) for text in X_train])\n",
        "X_val_rusvec = np.array([get_text_vector(text, model_rusvectores) for text in X_val])\n",
        "X_test_rusvec = np.array([get_text_vector(text, model_rusvectores) for text in X_test])\n",
        "\n",
        "# 3. Navec\n",
        "X_train_navec = np.array([get_text_vector(text, model_navec) for text in X_train])\n",
        "X_val_navec = np.array([get_text_vector(text, model_navec) for text in X_val])\n",
        "X_test_navec = np.array([get_text_vector(text, model_navec) for text in X_test])"
      ],
      "metadata": {
        "id": "pgqQW-d5AEhk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем метки классов\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Обучение логистической регрессии для каждой модели эмбеддингов\n",
        "# 1. Для нашей модели Word2Vec\n",
        "lr_w2v = LogisticRegression(max_iter=1000, C=1.0, random_state=1)\n",
        "lr_w2v.fit(X_train_w2v, y_train)\n",
        "\n",
        "# 2. Для RusVectores\n",
        "lr_rusvec = LogisticRegression(max_iter=1000, C=1.0, random_state=1)\n",
        "lr_rusvec.fit(X_train_rusvec, y_train)\n",
        "\n",
        "# 3. Для Navec\n",
        "lr_navec = LogisticRegression(max_iter=1000, C=1.0, random_state=1)\n",
        "lr_navec.fit(X_train_navec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Qhc5DaJJA-am",
        "outputId": "7d710d3e-180c-4377-86ca-966f7a7ea85f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=1)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка на валидационной выборке\n",
        "# 1. Для нашей модели Word2Vec\n",
        "y_val_pred_w2v = lr_w2v.predict(X_val_w2v)\n",
        "val_accuracy_w2v = accuracy_score(y_val, y_val_pred_w2v)\n",
        "print(f\"Accuracy на валидационной выборке (наша Word2Vec): {val_accuracy_w2v:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_w2v))\n",
        "\n",
        "# 2. Для RusVectores\n",
        "y_val_pred_rusvec = lr_rusvec.predict(X_val_rusvec)\n",
        "val_accuracy_rusvec = accuracy_score(y_val, y_val_pred_rusvec)\n",
        "print(f\"Accuracy на валидационной выборке (RusVectores): {val_accuracy_rusvec:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_rusvec))\n",
        "\n",
        "# 3. Для Navec\n",
        "y_val_pred_navec = lr_navec.predict(X_val_navec)\n",
        "val_accuracy_navec = accuracy_score(y_val, y_val_pred_navec)\n",
        "print(f\"Accuracy на валидационной выборке (Navec): {val_accuracy_navec:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_navec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE0XgWF0CdF2",
        "outputId": "b61bfb6e-4934-4899-a337-850ab54d25ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на валидационной выборке (наша Word2Vec): 0.8345\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82       610\n",
            "           1       0.85      0.78      0.82       408\n",
            "           2       0.78      0.83      0.80       682\n",
            "           3       0.79      0.78      0.78       772\n",
            "           4       0.90      0.88      0.89       667\n",
            "           5       0.81      0.87      0.84      1342\n",
            "           6       0.89      0.86      0.88       701\n",
            "           7       0.80      0.64      0.71       238\n",
            "           8       0.74      0.78      0.76      1381\n",
            "           9       0.79      0.74      0.76       536\n",
            "          10       0.96      0.97      0.96      1129\n",
            "          11       0.90      0.83      0.86       427\n",
            "          12       0.84      0.84      0.84       975\n",
            "\n",
            "    accuracy                           0.83      9868\n",
            "   macro avg       0.84      0.82      0.83      9868\n",
            "weighted avg       0.84      0.83      0.83      9868\n",
            "\n",
            "Accuracy на валидационной выборке (RusVectores): 0.1360\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       610\n",
            "           1       0.00      0.00      0.00       408\n",
            "           2       0.00      0.00      0.00       682\n",
            "           3       0.00      0.00      0.00       772\n",
            "           4       0.00      0.00      0.00       667\n",
            "           5       0.14      1.00      0.24      1342\n",
            "           6       0.00      0.00      0.00       701\n",
            "           7       0.00      0.00      0.00       238\n",
            "           8       0.00      0.00      0.00      1381\n",
            "           9       0.00      0.00      0.00       536\n",
            "          10       0.00      0.00      0.00      1129\n",
            "          11       0.00      0.00      0.00       427\n",
            "          12       0.00      0.00      0.00       975\n",
            "\n",
            "    accuracy                           0.14      9868\n",
            "   macro avg       0.01      0.08      0.02      9868\n",
            "weighted avg       0.02      0.14      0.03      9868\n",
            "\n",
            "Accuracy на валидационной выборке (Navec): 0.8178\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83       610\n",
            "           1       0.82      0.79      0.80       408\n",
            "           2       0.75      0.81      0.78       682\n",
            "           3       0.75      0.76      0.75       772\n",
            "           4       0.87      0.86      0.86       667\n",
            "           5       0.81      0.84      0.82      1342\n",
            "           6       0.87      0.85      0.86       701\n",
            "           7       0.76      0.59      0.67       238\n",
            "           8       0.73      0.75      0.74      1381\n",
            "           9       0.76      0.72      0.74       536\n",
            "          10       0.95      0.96      0.95      1129\n",
            "          11       0.89      0.84      0.86       427\n",
            "          12       0.83      0.83      0.83       975\n",
            "\n",
            "    accuracy                           0.82      9868\n",
            "   macro avg       0.82      0.80      0.81      9868\n",
            "weighted avg       0.82      0.82      0.82      9868\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(X_train)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "rFietfrNOQVC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector = tfidf_vectorizer.transform(['называть регион россия с самой высокий смертность'])\n",
        "\n",
        "nonzero_indices = tfidf_vector.nonzero()[1]\n",
        "nonzero_indices\n",
        "tfidf_weights = tfidf_vector.data\n",
        "words = [feature_names[idx] for idx in nonzero_indices]\n",
        "\n",
        "for word, weight in zip(words, tfidf_weights):\n",
        "    print(f\"{word}: {weight}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHKt7p-SvLnz",
        "outputId": "82ffd54b-e596-4517-d57b-9bdc5868f9fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "высокий: 0.3879544967330891\n",
            "называть: 0.40634769876295623\n",
            "регион: 0.3641314121990146\n",
            "россия: 0.19894026947032442\n",
            "смертность: 0.7156842460244959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Оригинал:\", df['title'][0])\n",
        "print(\"Нормализованный:\", df['normalized_title'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db_X4uvnwh1D",
        "outputId": "73ef5ec2-5703-498d-80b6-3a74f6b8a7b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оригинал: Названы регионы России с самой высокой смертностью от рака\n",
            "Нормализованный: назвать регион россия с сам высокий смертность от рак\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Функция для создания TF-IDF взвешенных векторов\n",
        "def get_tfidf_weighted_vector(text, word_vectors, vector_size=300):\n",
        "    tfidf_vector = tfidf_vectorizer.transform([text])\n",
        "\n",
        "    nonzero_indices = tfidf_vector.nonzero()[1]\n",
        "    tfidf_weights = tfidf_vector.data\n",
        "    words = [feature_names[idx] for idx in nonzero_indices]\n",
        "\n",
        "    # Вычисляем взвешенную сумму векторов слов\n",
        "    weighted_sum = np.zeros(vector_size)\n",
        "    total_weight = 0\n",
        "\n",
        "    for word, weight in zip(words, tfidf_weights):\n",
        "        if word in word_vectors:\n",
        "            weighted_sum += word_vectors[word] * weight\n",
        "            total_weight += weight\n",
        "\n",
        "    # Нормализуем по сумме весов\n",
        "    if total_weight > 0:\n",
        "        return weighted_sum / total_weight\n",
        "    else:\n",
        "        # Если не нашли слов с TF-IDF весами, используем обычное усреднение\n",
        "        tokens = text.split()\n",
        "        found_vectors = [word_vectors[token] for token in tokens if token in word_vectors]\n",
        "        if found_vectors:\n",
        "            return np.mean(found_vectors, axis=0)\n",
        "        else:\n",
        "            return np.zeros(vector_size)\n",
        "\n",
        "# 3. Создаем TF-IDF взвешенные векторы для наборов данных\n",
        "X_train_tfidf_weighted = np.array([get_tfidf_weighted_vector(text, w2v_model.wv) for text in X_train])\n",
        "X_val_tfidf_weighted = np.array([get_tfidf_weighted_vector(text, w2v_model.wv) for text in X_val])\n",
        "X_train_tfidf_weighted\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 5. Обучаем логистическую регрессию на TF-IDF взвешенных векторах\n",
        "lr_tfidf_weighted = LogisticRegression(max_iter=1000, C=1.0, random_state=1)\n",
        "lr_tfidf_weighted.fit(X_train_tfidf_weighted, y_train_encoded)\n",
        "\n",
        "# 6. Оцениваем модель на валидационной выборке\n",
        "y_val_pred = lr_tfidf_weighted.predict(X_val_tfidf_weighted)\n",
        "val_accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
        "print(f\"Accuracy на валидационной выборке (Word2Vec с TF-IDF взвешиванием): {val_accuracy:.4f}\")\n",
        "print(classification_report(y_val_encoded, y_val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK6exORoFL18",
        "outputId": "bfda4c05-1663-4f3d-ed7f-f75ce6b1518a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на валидационной выборке (Word2Vec с TF-IDF взвешиванием): 0.8359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.82       610\n",
            "           1       0.86      0.77      0.82       408\n",
            "           2       0.77      0.83      0.80       682\n",
            "           3       0.79      0.80      0.79       772\n",
            "           4       0.91      0.88      0.89       667\n",
            "           5       0.82      0.86      0.84      1342\n",
            "           6       0.89      0.86      0.88       701\n",
            "           7       0.80      0.69      0.74       238\n",
            "           8       0.75      0.78      0.76      1381\n",
            "           9       0.79      0.72      0.76       536\n",
            "          10       0.97      0.97      0.97      1129\n",
            "          11       0.90      0.84      0.87       427\n",
            "          12       0.84      0.85      0.84       975\n",
            "\n",
            "    accuracy                           0.84      9868\n",
            "   macro avg       0.84      0.82      0.83      9868\n",
            "weighted avg       0.84      0.84      0.84      9868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка на валидационной выборке\n",
        "# 1. Для нашей модели Word2Vec\n",
        "y_val_pred_w2v = lr_w2v.predict(X_val_w2v)\n",
        "val_accuracy_w2v = accuracy_score(y_val, y_val_pred_w2v)\n",
        "print(f\"Accuracy на валидационной выборке (наша Word2Vec): {val_accuracy_w2v:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_w2v))\n",
        "\n",
        "# 2. Для RusVectores\n",
        "y_val_pred_rusvec = lr_rusvec.predict(X_val_rusvec)\n",
        "val_accuracy_rusvec = accuracy_score(y_val, y_val_pred_rusvec)\n",
        "print(f\"Accuracy на валидационной выборке (RusVectores): {val_accuracy_rusvec:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_rusvec))\n",
        "\n",
        "# 3. Для Navec\n",
        "y_val_pred_navec = lr_navec.predict(X_val_navec)\n",
        "val_accuracy_navec = accuracy_score(y_val, y_val_pred_navec)\n",
        "print(f\"Accuracy на валидационной выборке (Navec): {val_accuracy_navec:.4f}\")\n",
        "print(classification_report(y_val, y_val_pred_navec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmDxFz0ZD5pR",
        "outputId": "9be4be6b-69bf-44ca-df5a-a2aeeac8a580"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на валидационной выборке (наша Word2Vec): 0.8345\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82       610\n",
            "           1       0.85      0.78      0.82       408\n",
            "           2       0.78      0.83      0.80       682\n",
            "           3       0.79      0.78      0.78       772\n",
            "           4       0.90      0.88      0.89       667\n",
            "           5       0.81      0.87      0.84      1342\n",
            "           6       0.89      0.86      0.88       701\n",
            "           7       0.80      0.64      0.71       238\n",
            "           8       0.74      0.78      0.76      1381\n",
            "           9       0.79      0.74      0.76       536\n",
            "          10       0.96      0.97      0.96      1129\n",
            "          11       0.90      0.83      0.86       427\n",
            "          12       0.84      0.84      0.84       975\n",
            "\n",
            "    accuracy                           0.83      9868\n",
            "   macro avg       0.84      0.82      0.83      9868\n",
            "weighted avg       0.84      0.83      0.83      9868\n",
            "\n",
            "Accuracy на валидационной выборке (RusVectores): 0.1360\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       610\n",
            "           1       0.00      0.00      0.00       408\n",
            "           2       0.00      0.00      0.00       682\n",
            "           3       0.00      0.00      0.00       772\n",
            "           4       0.00      0.00      0.00       667\n",
            "           5       0.14      1.00      0.24      1342\n",
            "           6       0.00      0.00      0.00       701\n",
            "           7       0.00      0.00      0.00       238\n",
            "           8       0.00      0.00      0.00      1381\n",
            "           9       0.00      0.00      0.00       536\n",
            "          10       0.00      0.00      0.00      1129\n",
            "          11       0.00      0.00      0.00       427\n",
            "          12       0.00      0.00      0.00       975\n",
            "\n",
            "    accuracy                           0.14      9868\n",
            "   macro avg       0.01      0.08      0.02      9868\n",
            "weighted avg       0.02      0.14      0.03      9868\n",
            "\n",
            "Accuracy на валидационной выборке (Navec): 0.8178\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83       610\n",
            "           1       0.82      0.79      0.80       408\n",
            "           2       0.75      0.81      0.78       682\n",
            "           3       0.75      0.76      0.75       772\n",
            "           4       0.87      0.86      0.86       667\n",
            "           5       0.81      0.84      0.82      1342\n",
            "           6       0.87      0.85      0.86       701\n",
            "           7       0.76      0.59      0.67       238\n",
            "           8       0.73      0.75      0.74      1381\n",
            "           9       0.76      0.72      0.74       536\n",
            "          10       0.95      0.96      0.95      1129\n",
            "          11       0.89      0.84      0.86       427\n",
            "          12       0.83      0.83      0.83       975\n",
            "\n",
            "    accuracy                           0.82      9868\n",
            "   macro avg       0.82      0.80      0.81      9868\n",
            "weighted avg       0.82      0.82      0.82      9868\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим TF-IDF взвешенные векторы\n",
        "X_train_tfidf_weighted = np.array([get_tfidf_weighted_vector(text, word_vectors, 300) for text in X_train])\n",
        "X_test_tfidf_weighted = np.array([get_tfidf_weighted_vector(text, word_vectors, 300) for text in X_test])\n",
        "\n",
        "# Обучим логистическую регрессию на TF-IDF взвешенных векторах\n",
        "lr_tfidf_weighted = LogisticRegression(max_iter=1000, C=1.0, random_state=1)\n",
        "lr_tfidf_weighted.fit(X_train_tfidf_weighted, y_train)\n",
        "\n",
        "# ФИНАЛЬНОЕ СРАВНЕНИЕ НА ТЕСТОВОЙ ВЫБОРКЕ\n",
        "# 1. Для нашей модели Word2Vec\n",
        "y_test_pred_w2v = lr_w2v.predict(X_test_w2v)\n",
        "test_accuracy_w2v = accuracy_score(y_test, y_test_pred_w2v)\n",
        "print(f\"Accuracy на тестовой выборке (наша Word2Vec): {test_accuracy_w2v:.4f}\")\n",
        "print(classification_report(y_test, y_test_pred_w2v))\n",
        "\n",
        "# 2. Для RusVectores\n",
        "y_test_pred_rusvec = lr_rusvec.predict(X_test_rusvec)\n",
        "test_accuracy_rusvec = accuracy_score(y_test, y_test_pred_rusvec)\n",
        "print(f\"Accuracy на тестовой выборке (RusVectores): {test_accuracy_rusvec:.4f}\")\n",
        "print(classification_report(y_test, y_test_pred_rusvec))\n",
        "\n",
        "# 3. Для Navec\n",
        "y_test_pred_navec = lr_navec.predict(X_test_navec)\n",
        "test_accuracy_navec = accuracy_score(y_test, y_test_pred_navec)\n",
        "print(f\"Accuracy на тестовой выборке (Navec): {test_accuracy_navec:.4f}\")\n",
        "print(classification_report(y_test, y_test_pred_navec))\n",
        "\n",
        "# 4. Для Word2Vec с TF-IDF взвешиванием\n",
        "y_test_pred_tfidf = lr_tfidf_weighted.predict(X_test_tfidf_weighted)\n",
        "test_accuracy_tfidf = accuracy_score(y_test, y_test_pred_tfidf)\n",
        "print(f\"Accuracy на тестовой выборке (Word2Vec с TF-IDF взвешиванием): {test_accuracy_tfidf:.4f}\")\n",
        "print(classification_report(y_test, y_test_pred_tfidf))\n",
        "\n",
        "# Сравнение всех моделей\n",
        "print(\"\\nСравнение accuracy всех моделей на тестовой выборке:\")\n",
        "print(f\"Word2Vec: {test_accuracy_w2v:.4f}\")\n",
        "print(f\"RusVectores: {test_accuracy_rusvec:.4f}\")\n",
        "print(f\"Navec: {test_accuracy_navec:.4f}\")\n",
        "print(f\"Word2Vec с TF-IDF взвешиванием: {test_accuracy_tfidf:.4f}\")\n",
        "\n",
        "# Определим лучшую модель\n",
        "best_accuracy = max(test_accuracy_w2v, test_accuracy_rusvec, test_accuracy_navec, test_accuracy_tfidf)\n",
        "if best_accuracy == test_accuracy_w2v:\n",
        "    print(\"\\nЛучшая модель: Word2Vec\")\n",
        "elif best_accuracy == test_accuracy_rusvec:\n",
        "    print(\"\\nЛучшая модель: RusVectores\")\n",
        "elif best_accuracy == test_accuracy_navec:\n",
        "    print(\"\\nЛучшая модель: Navec\")\n",
        "else:\n",
        "    print(\"\\nЛучшая модель: Word2Vec с TF-IDF взвешиванием\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0UslY2fEbF4",
        "outputId": "90abedd4-bb3a-41ee-dc89-4fca9d007113"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на тестовой выборке (наша Word2Vec): 0.8370\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84       655\n",
            "           1       0.85      0.82      0.83       397\n",
            "           2       0.77      0.83      0.80       614\n",
            "           3       0.79      0.75      0.77       767\n",
            "           4       0.92      0.89      0.91       650\n",
            "           5       0.83      0.87      0.85      1380\n",
            "           6       0.91      0.89      0.90       738\n",
            "           7       0.77      0.65      0.70       243\n",
            "           8       0.75      0.78      0.77      1428\n",
            "           9       0.76      0.73      0.74       539\n",
            "          10       0.95      0.96      0.95      1029\n",
            "          11       0.90      0.85      0.88       406\n",
            "          12       0.84      0.85      0.84      1021\n",
            "\n",
            "    accuracy                           0.84      9867\n",
            "   macro avg       0.84      0.82      0.83      9867\n",
            "weighted avg       0.84      0.84      0.84      9867\n",
            "\n",
            "Accuracy на тестовой выборке (RusVectores): 0.1399\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       655\n",
            "           1       0.00      0.00      0.00       397\n",
            "           2       0.00      0.00      0.00       614\n",
            "           3       0.00      0.00      0.00       767\n",
            "           4       0.00      0.00      0.00       650\n",
            "           5       0.14      1.00      0.25      1380\n",
            "           6       0.00      0.00      0.00       738\n",
            "           7       0.00      0.00      0.00       243\n",
            "           8       0.00      0.00      0.00      1428\n",
            "           9       0.00      0.00      0.00       539\n",
            "          10       0.00      0.00      0.00      1029\n",
            "          11       0.00      0.00      0.00       406\n",
            "          12       0.00      0.00      0.00      1021\n",
            "\n",
            "    accuracy                           0.14      9867\n",
            "   macro avg       0.01      0.08      0.02      9867\n",
            "weighted avg       0.02      0.14      0.03      9867\n",
            "\n",
            "Accuracy на тестовой выборке (Navec): 0.8218\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       655\n",
            "           1       0.82      0.83      0.83       397\n",
            "           2       0.75      0.81      0.78       614\n",
            "           3       0.77      0.75      0.76       767\n",
            "           4       0.90      0.88      0.89       650\n",
            "           5       0.82      0.85      0.83      1380\n",
            "           6       0.88      0.87      0.88       738\n",
            "           7       0.73      0.62      0.67       243\n",
            "           8       0.74      0.76      0.75      1428\n",
            "           9       0.75      0.72      0.74       539\n",
            "          10       0.95      0.96      0.95      1029\n",
            "          11       0.87      0.82      0.85       406\n",
            "          12       0.83      0.83      0.83      1021\n",
            "\n",
            "    accuracy                           0.82      9867\n",
            "   macro avg       0.82      0.81      0.81      9867\n",
            "weighted avg       0.82      0.82      0.82      9867\n",
            "\n",
            "Accuracy на тестовой выборке (Word2Vec с TF-IDF взвешиванием): 0.8357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       655\n",
            "           1       0.85      0.80      0.82       397\n",
            "           2       0.75      0.82      0.78       614\n",
            "           3       0.79      0.76      0.78       767\n",
            "           4       0.92      0.89      0.90       650\n",
            "           5       0.83      0.86      0.85      1380\n",
            "           6       0.91      0.89      0.90       738\n",
            "           7       0.76      0.69      0.73       243\n",
            "           8       0.75      0.78      0.76      1428\n",
            "           9       0.76      0.73      0.75       539\n",
            "          10       0.95      0.96      0.96      1029\n",
            "          11       0.91      0.86      0.88       406\n",
            "          12       0.84      0.85      0.85      1021\n",
            "\n",
            "    accuracy                           0.84      9867\n",
            "   macro avg       0.84      0.82      0.83      9867\n",
            "weighted avg       0.84      0.84      0.84      9867\n",
            "\n",
            "\n",
            "Сравнение accuracy всех моделей на тестовой выборке:\n",
            "Word2Vec: 0.8370\n",
            "RusVectores: 0.1399\n",
            "Navec: 0.8218\n",
            "Word2Vec с TF-IDF взвешиванием: 0.8357\n",
            "\n",
            "Лучшая модель: Word2Vec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}